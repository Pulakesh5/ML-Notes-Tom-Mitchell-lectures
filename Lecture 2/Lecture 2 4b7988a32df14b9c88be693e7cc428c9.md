# Lecture 2

- Function Approximation: The Big Picture
    
    f: X‚ÜíY X={x_1, x_2, ‚Ä¶, x_n}
    
    |X| = 2^n
    
    #of teachable functions : 2^|X|
    
    #of functions Decision Trees can representation : 2^|X|
    
    ![Screenshot 2023-07-30 at 4.06.00 PM.png](Lecture%202%204b7988a32df14b9c88be693e7cc428c9/Screenshot_2023-07-30_at_4.06.00_PM.png)
    
    <aside>
    üí° Occam‚Äôs razor: prefer the simplest hypothesis that first the data
    
    </aside>
    
- Overfitting in Decision Trees:
    
    Consider a hypothesis h and its 
    
    - Error rate over training data:  $error_{train}(h)$
    - True error rate over all data: $error_{true}(h)$
    
    We say h overfits the training data if
    
     $error_{true}(h)> error_{train}(h)$ 
    
    Amount of overfitting =  $error_{true}(h) - error_{train}(h)$
    
    ![Screenshot 2023-07-30 at 4.23.43 PM.png](Lecture%202%204b7988a32df14b9c88be693e7cc428c9/Screenshot_2023-07-30_at_4.23.43_PM.png)
    
    Reduced-Error Pruning:
    
    Split data into training and validation set
    
    Create tree that classifies training set correctly
    
    Do until further pruning is harmful:
    
    1. Evaluate impace on validation set of pruning each possible node
    2. Greedily remove the one that most improves validation set accuracy
    
    - Produces smallest version of most accurate subtree
    - What if data is limited?
    
- Supervised Learning or Function Approximation:
    
    ![Screenshot 2023-07-30 at 4.27.09 PM.png](Lecture%202%204b7988a32df14b9c88be693e7cc428c9/Screenshot_2023-07-30_at_4.27.09_PM.png)
    
    Core Aspects of Machine Learning:
    
    > Algorithm Design. How to Optimize? Computation Automatically generate rules that do well on observed data.
    > 
    
    > Confidence Bounds, Generalization (Labeled) Data Confidence for rule effectiveness on future data
    > 
    
    <aside>
    üí° Measure of entropy is a better splitting criterion
    
    </aside>
    
- Probability Overview
    - Events
        
        -discrete random variables, continuous random variables. compound events
        
    - Axioms of probability
        
        -What defines a reasonable theory of uncertainty
        
    - Independent events
    - Conditional probabilities
    - Bayes rule and beliefs
    - Joint probability distribution
    - Expectations
    - Independence, Conditional independence
    
    # Random Variables
    
    - Informally, A is a random variable if
        
        A denoted something about which we are uncertain
        
        perhaps the outcome of a randomized experiment
        
    - Examples
        
        A = True if a randomly drawn person from our class if female
        
        A = The hometown of a randomly drawn person from out class
        
        A = True if two randomly drawn persons from out class have same birthday
        
    - Define P(A) as ‚Äúthe fraction of possible worlds in which A is true‚Äù or ‚Äúthe fraction of times A holds, in repeated runs of the random experiment‚Äù
        
        The set of possible worlds is called the sample space, S
        
        A random variable A is function defined over S
        
        A: S‚Üí{0, 1}
        
    
    Definition of Conditional Probability:
    
    $$
    P(A|B)  = \frac {P(A \land B)} {P(B)}
    $$
    
    The chain rule:
    
    $$
    {P(A \land B)}  = P(A|B){P(B)}  
    $$
    
    In general,
    
    $$
    P(A\wedge B \wedge C) = P(A|BC) P(B|C)P(C)
    $$
    
    Bayes Rule:
    
    $$
    P(A\land B) = P(A|B)P(B) = P(B|A) P(A) \\ \\ P(A|B) =  \frac{P(B|A)P(A)}{P(B)}
    $$
    
    We call P(A) the ‚Äúprior‚Äù and P(A|B) the ‚Äúposterior‚Äù
    

Example:

A = you have the flu, B = you just coughed

P(A) = 0.05, P(B|A) = 0.8 and P(B|~A) = 0.2

what is P(A|B) = ?

*Solution:* 

$$
P(A|B) = \frac {P(B|A) P(A)} {P(B)} = \frac {P(B|A) P(A)} {P(B|A)P(A)+P(B| \sim A)P(\sim A)} \\ = \frac {0.8*0.05} {0.8*0.05 + 0.2*0.95} = \frac {0.04} {0.23} = 0.1739130435
$$